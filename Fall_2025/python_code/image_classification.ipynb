{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1jd4XY24VTY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to your dataset\n",
        "dataset_path = 'drive/MyDrive/Vanderbilt/SSDA/ML/Image classification'"
      ],
      "metadata": {
        "id": "3slV2Vpk4pmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categories for classification\n",
        "categories = ['recto', 'verso', 'double']"
      ],
      "metadata": {
        "id": "BXz2W00A42mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess the images\n",
        "def load_images(dataset_path, categories, image_size=(150, 150)):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for category in categories:\n",
        "        path = os.path.join(dataset_path, category)\n",
        "        for img_name in os.listdir(path):\n",
        "            img_path = os.path.join(path, img_name)\n",
        "            try:\n",
        "                # Load image, convert to grayscale, resize, and normalize\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                img = cv2.resize(img, image_size)\n",
        "                img = img / 255.0\n",
        "                data.append(img)\n",
        "                labels.append(category)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_name}: {e}\")\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ],
      "metadata": {
        "id": "YjseFGru49bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the data\n",
        "X, y = load_images(dataset_path, categories)\n",
        "X = np.expand_dims(X, axis=-1)  # add channel dimension (for grayscale images)"
      ],
      "metadata": {
        "id": "QsD_xok65Jo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_encoded = to_categorical(y_encoded, num_classes=len(categories))"
      ],
      "metadata": {
        "id": "zuEpwlsu6t2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "flEM8M-H7LR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model using Input()\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Input(shape=(150, 150, 1)))  # 150x150 image with 1 channel for grayscale\n",
        "\n",
        "# Add convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu')) # captures basic features like edges and corners, ReLU introduces non-linearity\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # downsamples feature maps to increase computational efficiency and prevent overfitting\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu')) # increases number of filters to allow model to learn more detailed features\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten and fully connected layers\n",
        "model.add(Flatten()) # converts 2D feature maps to 1D vectors to connect convolutional layers to fully connected layers\n",
        "model.add(Dense(128, activation='relu')) # combines features learned in convolutional layers to make predictions\n",
        "model.add(Dropout(0.5)) # randomly \"drops\" 50% of the neurons in the fully connected layer to prevent overfitting\n",
        "model.add(Dense(len(categories), activation='softmax')) # predicts the class with highest probability"
      ],
      "metadata": {
        "id": "PpxsY2c47SAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Adaptive Moment Estimation and categorical cross-entropy"
      ],
      "metadata": {
        "id": "FbA67YBuNaKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation to enhance training\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,  # Disable horizontal flip to avoid label ambiguity\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ],
      "metadata": {
        "id": "E9nTwgXGPH4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 15\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    steps_per_epoch=len(X_train) // batch_size,\n",
        "                    epochs=epochs)\n",
        "\n",
        "# Save the model\n",
        "model.save('folio_classifier_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxZKzllYPOwG",
        "outputId": "a5cdf50f-d42e-4b1c-bad7-c9da4e90f7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.3875 - loss: 1.4722 - val_accuracy: 0.7179 - val_loss: 1.0454\n",
            "Epoch 2/15\n",
            "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.3571 - loss: 1.1241"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 448ms/step - accuracy: 0.3571 - loss: 1.1241 - val_accuracy: 0.5128 - val_loss: 0.9916\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.4552 - loss: 1.0137 - val_accuracy: 0.5128 - val_loss: 0.8968\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.4643 - loss: 0.9226 - val_accuracy: 0.5128 - val_loss: 0.8513\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.5917 - loss: 0.8176 - val_accuracy: 0.9231 - val_loss: 0.5612\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - accuracy: 0.8214 - loss: 0.6573 - val_accuracy: 1.0000 - val_loss: 0.4476\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9083 - loss: 0.4733 - val_accuracy: 1.0000 - val_loss: 0.2023\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - accuracy: 0.8571 - loss: 0.3203 - val_accuracy: 1.0000 - val_loss: 0.1284\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9865 - loss: 0.1742 - val_accuracy: 1.0000 - val_loss: 0.0177\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 169ms/step - accuracy: 0.9643 - loss: 0.0529 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9771 - loss: 0.0357 - val_accuracy: 1.0000 - val_loss: 1.4493e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - accuracy: 0.9643 - loss: 0.0475 - val_accuracy: 1.0000 - val_loss: 8.3254e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 9.7982e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCb8R870RQzQ",
        "outputId": "d3667625-3fcc-411c-f0ba-2082fb5b6d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.0334e-04\n",
            "Test accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Define a function to preprocess the input image and predict the class label\n",
        "def predict_folio_class(image_path, model):\n",
        "    # Define the image size your model was trained on (150x150 in this case)\n",
        "    image_size = (150, 150)\n",
        "\n",
        "    # Load the image from the provided path, convert to grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Resize the image to match the input size of the model\n",
        "    image = cv2.resize(image, image_size)\n",
        "\n",
        "    # Convert the image to a numpy array and normalize pixel values\n",
        "    image = img_to_array(image) / 255.0\n",
        "\n",
        "    # Expand dimensions to fit the model input shape (1, 150, 150, 1)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Use the model to predict the class label probabilities\n",
        "    predictions = model.predict(image)\n",
        "\n",
        "    # Get the index of the highest probability\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "    # Define the class labels (these should match your training labels)\n",
        "    class_labels = ['double', 'recto', 'verso']\n",
        "\n",
        "    # Map the predicted index to the corresponding class label\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "    return predicted_class_label"
      ],
      "metadata": {
        "id": "em5g8h56Rxhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_folio_class(\"drive/MyDrive/Vanderbilt/SSDA/ML/Image classification/recto/239746-0029.jpg\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JzKk6v3jR2jX",
        "outputId": "1bff4665-94b0-4785-ef4c-073a29c3cbd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'recto'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}